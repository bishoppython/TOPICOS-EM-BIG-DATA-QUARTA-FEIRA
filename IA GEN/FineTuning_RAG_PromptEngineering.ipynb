{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Fine-Tuning, RAG e Prompt Engineering\n\nEste notebook traz exemplos pr\u00e1ticos dos conceitos apresentados na aula."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83e\udde0 Fine-Tuning com Transformers (Exemplo Simplificado)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers datasets -q\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Carregar modelo e tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
        "\n",
        "# Dataset de exemplo\n",
        "dataset = load_dataset(\"codeparrot/github-jupyter-text\", split=\"train[:1%]\")\n",
        "def tokenize(example):\n",
        "    return tokenizer(example['content'], truncation=True, padding='max_length', max_length=128)\n",
        "tokenized_dataset = dataset.map(tokenize)\n",
        "\n",
        "# Argumentos de treino\n",
        "args = TrainingArguments(output_dir=\"./results\", per_device_train_batch_size=2, num_train_epochs=1)\n",
        "\n",
        "# Treinador\n",
        "trainer = Trainer(model=model, args=args, train_dataset=tokenized_dataset)\n",
        "# trainer.train()  # Descomente para executar o treino"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udd0d RAG (Retrieval-Augmented Generation) com FAISS e LangChain"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install langchain faiss-cpu sentence-transformers -q\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Dados simulados\n",
        "textos = [\"Python \u00e9 uma linguagem de programa\u00e7\u00e3o popular.\", \"Pandas \u00e9 uma biblioteca de an\u00e1lise de dados.\"]\n",
        "splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "docs = splitter.create_documents(textos)\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "db = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "# Modelo simulado (substitua por um modelo real se necess\u00e1rio)\n",
        "# llm = OpenAI()  # Requer chave da OpenAI\n",
        "# qa = RetrievalQA.from_chain_type(llm=llm, retriever=db.as_retriever())\n",
        "# print(qa.run(\"O que \u00e9 Pandas?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \u270d\ufe0f Prompt Engineering"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prompt simples\n",
        "prompt_simples = \"Explique o que \u00e9 HTML.\"\n",
        "\n",
        "# Prompt melhorado\n",
        "prompt_melhorado = (\n",
        "    \"Voc\u00ea \u00e9 um professor de web design. Explique o que \u00e9 HTML para um aluno iniciante, \"\n",
        "    \"usando analogias simples, como constru\u00e7\u00e3o civil.\"\n",
        ")\n",
        "print(\"Prompt Simples:\\n\", prompt_simples)\n",
        "print(\"\\nPrompt Melhorado:\\n\", prompt_melhorado)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}